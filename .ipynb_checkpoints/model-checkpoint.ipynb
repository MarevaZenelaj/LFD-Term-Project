{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "from keras import Model, Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "def read_csv_file(filename):\n",
    "    dataset = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        data = csv.reader(f, delimiter='\\n')\n",
    "        header = next(data)\n",
    "        numberColumns = len(header)\n",
    "        counter = 0\n",
    "        for row in data:\n",
    "            columns = list(row[0].split(','))\n",
    "            newcolumns = []\n",
    "            for number in columns:\n",
    "                newcolumns.append(float(number))\n",
    "\n",
    "            dataset.append(newcolumns)\n",
    "            counter += 1\n",
    "\n",
    "    dataset = np.asarray(dataset)\n",
    "    return dataset\n",
    "\n",
    "train = read_csv_file(\"train.csv\")\n",
    "labels = train[:,-1].astype(int)\n",
    "train = train[:,:-1]\n",
    "test = read_csv_file('test.csv')\n",
    "labels = keras.utils.to_categorical(labels, 2)\n",
    "print(\"train data: \", train.shape)\n",
    "print(\"test data: \", test.shape)\n",
    "print(np.unique(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 84 samples, validate on 36 samples\n",
      "Epoch 1/40\n",
      "84/84 [==============================] - 1s 16ms/step - loss: 0.2559 - acc: 0.4524 - val_loss: 0.2508 - val_acc: 0.4167\n",
      "Epoch 2/40\n",
      "84/84 [==============================] - 0s 204us/step - loss: 0.2487 - acc: 0.5476 - val_loss: 0.2497 - val_acc: 0.5000\n",
      "Epoch 3/40\n",
      "84/84 [==============================] - 0s 214us/step - loss: 0.2484 - acc: 0.5357 - val_loss: 0.2500 - val_acc: 0.5278\n",
      "Epoch 4/40\n",
      "84/84 [==============================] - 0s 222us/step - loss: 0.2460 - acc: 0.5357 - val_loss: 0.2438 - val_acc: 0.5833\n",
      "Epoch 5/40\n",
      "84/84 [==============================] - 0s 229us/step - loss: 0.2404 - acc: 0.6667 - val_loss: 0.2725 - val_acc: 0.4167\n",
      "Epoch 6/40\n",
      "84/84 [==============================] - 0s 226us/step - loss: 0.2384 - acc: 0.5357 - val_loss: 0.2655 - val_acc: 0.4444\n",
      "Epoch 7/40\n",
      "84/84 [==============================] - 0s 193us/step - loss: 0.2336 - acc: 0.5476 - val_loss: 0.2666 - val_acc: 0.4444\n",
      "Epoch 8/40\n",
      "84/84 [==============================] - 0s 272us/step - loss: 0.2290 - acc: 0.6548 - val_loss: 0.2642 - val_acc: 0.5000\n",
      "Epoch 9/40\n",
      "84/84 [==============================] - 0s 195us/step - loss: 0.2262 - acc: 0.6429 - val_loss: 0.2650 - val_acc: 0.5000\n",
      "Epoch 10/40\n",
      "84/84 [==============================] - 0s 209us/step - loss: 0.2225 - acc: 0.6429 - val_loss: 0.2473 - val_acc: 0.5278\n",
      "Epoch 11/40\n",
      "84/84 [==============================] - 0s 242us/step - loss: 0.2150 - acc: 0.6786 - val_loss: 0.2912 - val_acc: 0.4722\n",
      "Epoch 12/40\n",
      "84/84 [==============================] - 0s 232us/step - loss: 0.2206 - acc: 0.5714 - val_loss: 0.2945 - val_acc: 0.5000\n",
      "Epoch 13/40\n",
      "84/84 [==============================] - 0s 208us/step - loss: 0.2085 - acc: 0.7262 - val_loss: 0.2569 - val_acc: 0.5278\n",
      "Epoch 14/40\n",
      "84/84 [==============================] - 0s 257us/step - loss: 0.2028 - acc: 0.7381 - val_loss: 0.2837 - val_acc: 0.5000\n",
      "Epoch 15/40\n",
      "84/84 [==============================] - 0s 263us/step - loss: 0.1913 - acc: 0.7381 - val_loss: 0.2724 - val_acc: 0.5556\n",
      "Epoch 16/40\n",
      "84/84 [==============================] - 0s 282us/step - loss: 0.1878 - acc: 0.7381 - val_loss: 0.2833 - val_acc: 0.5556\n",
      "Epoch 17/40\n",
      "84/84 [==============================] - 0s 266us/step - loss: 0.1729 - acc: 0.7738 - val_loss: 0.2882 - val_acc: 0.5556\n",
      "Epoch 18/40\n",
      "84/84 [==============================] - 0s 290us/step - loss: 0.1669 - acc: 0.8333 - val_loss: 0.2857 - val_acc: 0.5278\n",
      "Epoch 19/40\n",
      "84/84 [==============================] - 0s 266us/step - loss: 0.1613 - acc: 0.7976 - val_loss: 0.2922 - val_acc: 0.5556\n",
      "Epoch 20/40\n",
      "84/84 [==============================] - 0s 264us/step - loss: 0.1585 - acc: 0.8214 - val_loss: 0.3083 - val_acc: 0.5556\n",
      "Epoch 21/40\n",
      "84/84 [==============================] - 0s 229us/step - loss: 0.1526 - acc: 0.8095 - val_loss: 0.2869 - val_acc: 0.4722\n",
      "Epoch 22/40\n",
      "84/84 [==============================] - 0s 225us/step - loss: 0.1636 - acc: 0.7619 - val_loss: 0.3399 - val_acc: 0.5000\n",
      "Epoch 23/40\n",
      "84/84 [==============================] - 0s 229us/step - loss: 0.1472 - acc: 0.7976 - val_loss: 0.3032 - val_acc: 0.4722\n",
      "Epoch 24/40\n",
      "84/84 [==============================] - 0s 227us/step - loss: 0.1314 - acc: 0.8333 - val_loss: 0.3237 - val_acc: 0.5278\n",
      "Epoch 25/40\n",
      "84/84 [==============================] - 0s 228us/step - loss: 0.1210 - acc: 0.8810 - val_loss: 0.3047 - val_acc: 0.4722\n",
      "Epoch 26/40\n",
      "84/84 [==============================] - 0s 228us/step - loss: 0.1166 - acc: 0.8690 - val_loss: 0.3244 - val_acc: 0.5278\n",
      "Epoch 27/40\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.1088 - acc: 0.8929 - val_loss: 0.3292 - val_acc: 0.5278\n",
      "Epoch 28/40\n",
      "84/84 [==============================] - 0s 221us/step - loss: 0.1104 - acc: 0.9048 - val_loss: 0.3255 - val_acc: 0.4444\n",
      "Epoch 29/40\n",
      "84/84 [==============================] - 0s 202us/step - loss: 0.1098 - acc: 0.8810 - val_loss: 0.3381 - val_acc: 0.5556\n",
      "Epoch 30/40\n",
      "84/84 [==============================] - 0s 197us/step - loss: 0.1087 - acc: 0.9167 - val_loss: 0.3525 - val_acc: 0.5278\n",
      "Epoch 31/40\n",
      "84/84 [==============================] - 0s 206us/step - loss: 0.1012 - acc: 0.9167 - val_loss: 0.3539 - val_acc: 0.5278\n",
      "Epoch 32/40\n",
      "84/84 [==============================] - 0s 219us/step - loss: 0.0970 - acc: 0.8810 - val_loss: 0.3430 - val_acc: 0.5556\n",
      "Epoch 33/40\n",
      "84/84 [==============================] - 0s 208us/step - loss: 0.0808 - acc: 0.9286 - val_loss: 0.3416 - val_acc: 0.5278\n",
      "Epoch 34/40\n",
      "84/84 [==============================] - 0s 201us/step - loss: 0.1039 - acc: 0.8690 - val_loss: 0.3649 - val_acc: 0.5000\n",
      "Epoch 35/40\n",
      "84/84 [==============================] - 0s 267us/step - loss: 0.0927 - acc: 0.8333 - val_loss: 0.3662 - val_acc: 0.4722\n",
      "Epoch 36/40\n",
      "84/84 [==============================] - 0s 281us/step - loss: 0.0998 - acc: 0.8690 - val_loss: 0.3667 - val_acc: 0.5278\n",
      "Epoch 37/40\n",
      "84/84 [==============================] - 0s 290us/step - loss: 0.0711 - acc: 0.9405 - val_loss: 0.3615 - val_acc: 0.5556\n",
      "Epoch 38/40\n",
      "84/84 [==============================] - 0s 273us/step - loss: 0.0730 - acc: 0.9167 - val_loss: 0.3674 - val_acc: 0.5556\n",
      "Epoch 39/40\n",
      "84/84 [==============================] - 0s 287us/step - loss: 0.0637 - acc: 0.9524 - val_loss: 0.3692 - val_acc: 0.5278\n",
      "Epoch 40/40\n",
      "84/84 [==============================] - 0s 269us/step - loss: 0.0644 - acc: 0.9524 - val_loss: 0.3842 - val_acc: 0.4722\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128,input_dim=595, activation='relu'))\n",
    "model.add(Dense(64, input_dim=128, activation='relu'))\n",
    "model.add(Dense(16, input_dim=64, activation='relu'))\n",
    "model.add(Dropout(0,3))\n",
    "model.add(Dense(2,input_dim=16, activation='softmax'))\n",
    "\n",
    "comp = model.compile(optimizer='adam', loss='mse', metrics=['acc'])\n",
    "history = model.fit(train, labels, epochs=40, batch_size = 16, validation_split=0.2)\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"submission.csv\", 'w') as f:\n",
    "    f.write(\"ID,Predicted\\n\")\n",
    "    for i in range(len(test)):\n",
    "        tstfile = test[i]\n",
    "        tstfile = np.reshape(tstfile, (1,595))\n",
    "        prediction = model.predict(tstfile)\n",
    "        if prediction[0][0] > prediction[0][1]:\n",
    "            writestr = str(i+1) + ','+ str(0) + '\\n'\n",
    "            f.write(writestr)\n",
    "    \n",
    "        elif prediction[0][0] < prediction[0][1]:\n",
    "            writestr = str(i+1) + ','+ str(1) + '\\n'\n",
    "            f.write(writestr)\n",
    "f.close()\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
